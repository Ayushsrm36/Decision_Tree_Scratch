{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "nuE79JseGPVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr6kxthzvam2"
      },
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "\n",
        "  def __init__(self,example_idx,left_child,right_child,criterion,\n",
        "               unique_classes,class_probabilities,criterion_value,\n",
        "               purest_feature_idx,division_mean):\n",
        "    \n",
        "    self.row_example_idx = example_idx\n",
        "    self.left_node = left_child\n",
        "    self.right_node = right_child\n",
        "    self.node_loss_func = criterion\n",
        "    self.unique_categories = unique_classes\n",
        "    self.class_posterior = class_probabilities\n",
        "    self.loss_func_value = criterion_value\n",
        "    self.imp_feature_idx = purest_feature_idx\n",
        "    self.cutpoint_value = division_mean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier:\n",
        "\n",
        "  def __init__(self,criterion=\"gini\",splitter=\"best\",max_depth=None,\n",
        "               min_samples_split=2,min_samples_leaf=1,\n",
        "               min_weight_fraction_leaf=0.0,max_features=None,\n",
        "               random_state=None,max_leaf_nodes=None,\n",
        "               min_impurity_decrease=0.0,class_weight=None,\n",
        "               ccp_alpha=0.0):\n",
        "    \n",
        "    self.loss_func = criterion\n",
        "    self.split_stopping = splitter\n",
        "    self.tree_max_depth = max_depth\n",
        "    self.min_examples_split = min_samples_split\n",
        "    self.min_examples_leaf = min_samples_leaf\n",
        "    self.min_example_fraction = min_weight_fraction_leaf\n",
        "    self.tree_features = max_features\n",
        "    self.seed = random_state\n",
        "    self.num_leaf_nodes = max_leaf_nodes\n",
        "    self.impurity_decrease_thresh = min_impurity_decrease\n",
        "    self.class_percentage = class_weight\n",
        "    self.pruning_param_value = ccp_alpha\n",
        "\n",
        "  def fit(self,X,y,sample_weight=None,check_input=True):\n",
        "    X_copy = np.copy(X)\n",
        "    data = np.concatenate((X_copy,y),axis=1)\n",
        "    example_idx = np.arange(0,data.shape[0]).reshape(data.shape[0],1)\n",
        "    data = np.concatenate((data,example_idx),axis=1)\n",
        "\n",
        "\n",
        "    def loss_func_criterion_value(loss_func_criterion,divided_data):\n",
        "      if loss_func_criterion == \"self entropy\":\n",
        "        values, counts = np.unique(data[:,divided_data.shape[1]-2],\n",
        "                                   return_counts=True)\n",
        "        class_proba_dict = dict(zip(values,(1/divided_data.shape[0])*counts))\n",
        "        class_proba = np.array(list(class_proba_dict.values()))\n",
        "        loss_func_value = -np.sum((class_proba*np.log(class_proba)))\n",
        "        return class_proba_dict, loss_func_value\n",
        "      elif loss_func_criterion == \"mse\":\n",
        "        return {}, np.mean((divided_data[:,divided_data.shape[1]-2]-\\\n",
        "                           np.mean(divided_data[:,divided_data.shape[1]-2]))**2)"
      ],
      "metadata": {
        "id": "h1pAigy34g23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}